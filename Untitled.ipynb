{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<STARTING>\n",
      "Agent state: (2, 3, Down)\n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- - -) (- 1 -) (- 1 -) (- - -)\n",
      "1 (- - -) (- - 2) (- - -) (- - 2) (- - 1)\n",
      "2 (- 1 -) (- - -) (- 1 -) (- - -) (- - -)\n",
      "3 (- - -) (- 1 1) (V - -) (- - -) (- - -)\n",
      "4 (- - -) (- - -) (- - -) (- - -) (- - -)\n",
      "Agent performance: 100\n",
      "PERCEPT\n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- - -) (- 1 -) (- 1 -) (- - -)\n",
      "1 (- - -) (- - 2) (- - -) (- - 2) (- - 1)\n",
      "2 (- 1 -) (- - -) (- 1 -) (- - -) (- - -)\n",
      "3 (- - -) (- 1 1) (D - -) (- - -) (- - -)\n",
      "4 (- - -) (- - -) (- - -) (- - -) (- - -)\n",
      "<STEP 1>\n",
      "SELECTED ACTION: Turn\n",
      "Agent state: (2, 3, Left)\n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- - -) (- 1 -) (- 1 -) (- - -)\n",
      "1 (- - -) (- - 2) (- - -) (- - 2) (- - 1)\n",
      "2 (- 1 -) (- - -) (- 1 -) (- - -) (- - -)\n",
      "3 (- - -) (- 1 1) (V - -) (- - -) (- - -)\n",
      "4 (- - -) (- - -) (- - -) (- - -) (- - -)\n",
      "Agent performance: 99\n",
      "PERCEPT\n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- - -) (- 1 -) (- 1 -) (- - -)\n",
      "1 (- - -) (- - 2) (- - -) (- - 2) (- - 1)\n",
      "2 (- 1 -) (- - -) (- 1 -) (- - -) (- - -)\n",
      "3 (- - -) (- 1 1) (L - -) (- - -) (- - -)\n",
      "4 (- - -) (- - -) (- - -) (- - -) (- - -)\n",
      "<STEP 2>\n",
      "SELECTED ACTION: Advance\n",
      "Agent state: (1, 3, Left)\n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- - -) (- 1 -) (- 1 -) (- - -)\n",
      "1 (- - -) (- - 2) (- - -) (- - 2) (- - 1)\n",
      "2 (- 1 -) (- - -) (- 1 -) (- - -) (- - -)\n",
      "3 (- - -) (V - -) (V - -) (- - -) (- - -)\n",
      "4 (- - -) (- - -) (- - -) (- - -) (- - -)\n",
      "Agent performance: 103\n",
      "PERCEPT\n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- - -) (- 1 -) (- 1 -) (- - -)\n",
      "1 (- - -) (- - 2) (- - -) (- - 2) (- - 1)\n",
      "2 (- 1 -) (- - -) (- 1 -) (- - -) (- - -)\n",
      "3 (- - -) (L - -) (- - -) (- - -) (- - -)\n",
      "4 (- - -) (- - -) (- - -) (- - -) (- - -)\n",
      "<STEP 3>\n",
      "SELECTED ACTION: Advance\n",
      "Agent state: (0, 3, Left)\n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- - -) (- 1 -) (- 1 -) (- - -)\n",
      "1 (- - -) (- - 2) (- - -) (- - 2) (- - 1)\n",
      "2 (- 1 -) (- - -) (- 1 -) (- - -) (- - -)\n",
      "3 (V - -) (V - -) (V - -) (- - -) (- - -)\n",
      "4 (- - -) (- - -) (- - -) (- - -) (- - -)\n",
      "Agent performance: 102\n",
      "PERCEPT\n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- - -) (- 1 -) (- 1 -) (- - -)\n",
      "1 (- - -) (- - 2) (- - -) (- - 2) (- - 1)\n",
      "2 (- 1 -) (- - -) (- 1 -) (- - -) (- - -)\n",
      "3 (L - -) (- - -) (- - -) (- - -) (- - -)\n",
      "4 (- - -) (- - -) (- - -) (- - -) (- - -)\n",
      "<STEP 4>\n",
      "SELECTED ACTION: Turn\n",
      "Agent state: (0, 3, Up)\n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- - -) (- 1 -) (- 1 -) (- - -)\n",
      "1 (- - -) (- - 2) (- - -) (- - 2) (- - 1)\n",
      "2 (- 1 -) (- - -) (- 1 -) (- - -) (- - -)\n",
      "3 (V - -) (V - -) (V - -) (- - -) (- - -)\n",
      "4 (- - -) (- - -) (- - -) (- - -) (- - -)\n",
      "Agent performance: 101\n",
      "PERCEPT\n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- - -) (- 1 -) (- 1 -) (- - -)\n",
      "1 (- - -) (- - 2) (- - -) (- - 2) (- - 1)\n",
      "2 (- 1 -) (- - -) (- 1 -) (- - -) (- - -)\n",
      "3 (U - -) (- - -) (- - -) (- - -) (- - -)\n",
      "4 (- - -) (- - -) (- - -) (- - -) (- - -)\n",
      "<STEP 5>\n",
      "SELECTED ACTION: Advance\n",
      "Agent state: (0, 2, Up)\n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- - -) (- 1 -) (- 1 -) (- - -)\n",
      "1 (- - -) (- - 2) (- - -) (- - 2) (- - 1)\n",
      "2 (V - -) (- - -) (- 1 -) (- - -) (- - -)\n",
      "3 (V - -) (V - -) (V - -) (- - -) (- - -)\n",
      "4 (- - -) (- - -) (- - -) (- - -) (- - -)\n",
      "Agent performance: 110\n",
      "PERCEPT\n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- - -) (- 1 -) (- 1 -) (- - -)\n",
      "1 (- - -) (- - 2) (- - -) (- - 2) (- - 1)\n",
      "2 (U - -) (- - -) (- 1 -) (- - -) (- - -)\n",
      "3 (- - -) (- - -) (- - -) (- - -) (- - -)\n",
      "4 (- - -) (- - -) (- - -) (- - -) (- - -)\n",
      "<STEP 6>\n",
      "SELECTED ACTION: Advance\n",
      "Agent state: (0, 1, Up)\n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- - -) (- 1 -) (- 1 -) (- - -)\n",
      "1 (V - -) (- - 2) (- - -) (- - 2) (- - 1)\n",
      "2 (V - -) (- - -) (- 1 -) (- - -) (- - -)\n",
      "3 (V - -) (V - -) (V - -) (- - -) (- - -)\n",
      "4 (- - -) (- - -) (- - -) (- - -) (- - -)\n",
      "Agent performance: 109\n",
      "PERCEPT\n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- - -) (- 1 -) (- 1 -) (- - -)\n",
      "1 (U - -) (- - 2) (- - -) (- - 2) (- - 1)\n",
      "2 (- - -) (- - -) (- 1 -) (- - -) (- - -)\n",
      "3 (- - -) (- - -) (- - -) (- - -) (- - -)\n",
      "4 (- - -) (- - -) (- - -) (- - -) (- - -)\n",
      "<STEP 7>\n",
      "SELECTED ACTION: Advance\n",
      "Agent state: (0, 0, Up)\n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (V - -) (- - -) (- 1 -) (- 1 -) (- - -)\n",
      "1 (V - -) (- - 2) (- - -) (- - 2) (- - 1)\n",
      "2 (V - -) (- - -) (- 1 -) (- - -) (- - -)\n",
      "3 (V - -) (V - -) (V - -) (- - -) (- - -)\n",
      "4 (- - -) (- - -) (- - -) (- - -) (- - -)\n",
      "Agent performance: 108\n",
      "PERCEPT\n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (U - -) (- - -) (- 1 -) (- 1 -) (- - -)\n",
      "1 (- - -) (- - 2) (- - -) (- - 2) (- - 1)\n",
      "2 (- - -) (- - -) (- 1 -) (- - -) (- - -)\n",
      "3 (- - -) (- - -) (- - -) (- - -) (- - -)\n",
      "4 (- - -) (- - -) (- - -) (- - -) (- - -)\n",
      "<STEP 8>\n",
      "SELECTED ACTION: Turn\n",
      "Agent state: (0, 0, Right)\n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (V - -) (- - -) (- 1 -) (- 1 -) (- - -)\n",
      "1 (V - -) (- - 2) (- - -) (- - 2) (- - 1)\n",
      "2 (V - -) (- - -) (- 1 -) (- - -) (- - -)\n",
      "3 (V - -) (V - -) (V - -) (- - -) (- - -)\n",
      "4 (- - -) (- - -) (- - -) (- - -) (- - -)\n",
      "Agent performance: 107\n",
      "PERCEPT\n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (R - -) (- - -) (- 1 -) (- 1 -) (- - -)\n",
      "1 (- - -) (- - 2) (- - -) (- - 2) (- - 1)\n",
      "2 (- - -) (- - -) (- 1 -) (- - -) (- - -)\n",
      "3 (- - -) (- - -) (- - -) (- - -) (- - -)\n",
      "4 (- - -) (- - -) (- - -) (- - -) (- - -)\n",
      "<STEP 9>\n",
      "SELECTED ACTION: Advance\n",
      "Agent state: (1, 0, Right)\n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (V - -) (V - -) (- 1 -) (- 1 -) (- - -)\n",
      "1 (V - -) (- - 2) (- - -) (- - 2) (- - 1)\n",
      "2 (V - -) (- - -) (- 1 -) (- - -) (- - -)\n",
      "3 (V - -) (V - -) (V - -) (- - -) (- - -)\n",
      "4 (- - -) (- - -) (- - -) (- - -) (- - -)\n",
      "Agent performance: 106\n",
      "PERCEPT\n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (R - -) (- 1 -) (- 1 -) (- - -)\n",
      "1 (- - -) (- - 2) (- - -) (- - 2) (- - 1)\n",
      "2 (- - -) (- - -) (- 1 -) (- - -) (- - -)\n",
      "3 (- - -) (- - -) (- - -) (- - -) (- - -)\n",
      "4 (- - -) (- - -) (- - -) (- - -) (- - -)\n",
      "<STEP 10>\n",
      "SELECTED ACTION: Advance\n",
      "Agent state: (2, 0, Right)\n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (V - -) (V - -) (V - -) (- 1 -) (- - -)\n",
      "1 (V - -) (- - 2) (- - -) (- - 2) (- - 1)\n",
      "2 (V - -) (- - -) (- 1 -) (- - -) (- - -)\n",
      "3 (V - -) (V - -) (V - -) (- - -) (- - -)\n",
      "4 (- - -) (- - -) (- - -) (- - -) (- - -)\n",
      "Agent performance: 115\n",
      "PERCEPT\n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- - -) (R - -) (- 1 -) (- - -)\n",
      "1 (- - -) (- - 2) (- - -) (- - 2) (- - 1)\n",
      "2 (- - -) (- - -) (- 1 -) (- - -) (- - -)\n",
      "3 (- - -) (- - -) (- - -) (- - -) (- - -)\n",
      "4 (- - -) (- - -) (- - -) (- - -) (- - -)\n",
      "<STEP 11>\n",
      "SELECTED ACTION: Advance\n",
      "Agent state: (3, 0, Right)\n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (V - -) (V - -) (V - -) (V - -) (- - -)\n",
      "1 (V - -) (- - 2) (- - -) (- - 2) (- - 1)\n",
      "2 (V - -) (- - -) (- 1 -) (- - -) (- - -)\n",
      "3 (V - -) (V - -) (V - -) (- - -) (- - -)\n",
      "4 (- - -) (- - -) (- - -) (- - -) (- - -)\n",
      "Agent performance: 124\n",
      "PERCEPT\n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- - -) (- - -) (R - -) (- - -)\n",
      "1 (- - -) (- - 2) (- - -) (- - 2) (- - 1)\n",
      "2 (- - -) (- - -) (- 1 -) (- - -) (- - -)\n",
      "3 (- - -) (- - -) (- - -) (- - -) (- - -)\n",
      "4 (- - -) (- - -) (- - -) (- - -) (- - -)\n",
      "<STEP 12>\n",
      "SELECTED ACTION: Turn\n",
      "Agent state: (3, 0, Down)\n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (V - -) (V - -) (V - -) (V - -) (- - -)\n",
      "1 (V - -) (- - 2) (- - -) (- - 2) (- - 1)\n",
      "2 (V - -) (- - -) (- 1 -) (- - -) (- - -)\n",
      "3 (V - -) (V - -) (V - -) (- - -) (- - -)\n",
      "4 (- - -) (- - -) (- - -) (- - -) (- - -)\n",
      "Agent performance: 123\n",
      "PERCEPT\n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- - -) (- - -) (D - -) (- - -)\n",
      "1 (- - -) (- - 2) (- - -) (- - 2) (- - 1)\n",
      "2 (- - -) (- - -) (- 1 -) (- - -) (- - -)\n",
      "3 (- - -) (- - -) (- - -) (- - -) (- - -)\n",
      "4 (- - -) (- - -) (- - -) (- - -) (- - -)\n",
      "<STEP 13>\n",
      "SELECTED ACTION: Advance\n",
      "Agent state: (3, 1, Down)\n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (V - -) (V - -) (V - -) (V - -) (- - -)\n",
      "1 (V - -) (- - 2) (- - -) (V - 1) (- - 1)\n",
      "2 (V - -) (- - -) (- 1 -) (- - -) (- - -)\n",
      "3 (V - -) (V - -) (V - -) (- - -) (- - -)\n",
      "4 (- - -) (- - -) (- - -) (- - -) (- - -)\n",
      "Agent performance: 117\n",
      "PERCEPT\n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- - -) (- - -) (- - -) (- - -)\n",
      "1 (- - -) (- - 2) (- - -) (D - 1) (- - 1)\n",
      "2 (- - -) (- - -) (- 1 -) (- - -) (- - -)\n",
      "3 (- - -) (- - -) (- - -) (- - -) (- - -)\n",
      "4 (- - -) (- - -) (- - -) (- - -) (- - -)\n",
      "<STEP 14>\n",
      "SELECTED ACTION: Advance\n",
      "Agent state: (3, 2, Down)\n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (V - -) (V - -) (V - -) (V - -) (- - -)\n",
      "1 (V - -) (- - 2) (- - -) (V - 1) (- - 1)\n",
      "2 (V - -) (- - -) (- 1 -) (V - -) (- - -)\n",
      "3 (V - -) (V - -) (V - -) (- - -) (- - -)\n",
      "4 (- - -) (- - -) (- - -) (- - -) (- - -)\n",
      "Agent performance: 116\n",
      "PERCEPT\n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- - -) (- - -) (- - -) (- - -)\n",
      "1 (- - -) (- - 2) (- - -) (- - 1) (- - 1)\n",
      "2 (- - -) (- - -) (- 1 -) (D - -) (- - -)\n",
      "3 (- - -) (- - -) (- - -) (- - -) (- - -)\n",
      "4 (- - -) (- - -) (- - -) (- - -) (- - -)\n",
      "<STEP 15>\n",
      "SELECTED ACTION: Turn\n",
      "Agent state: (3, 2, Left)\n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (V - -) (V - -) (V - -) (V - -) (- - -)\n",
      "1 (V - -) (- - 2) (- - -) (V - 1) (- - 1)\n",
      "2 (V - -) (- - -) (- 1 -) (V - -) (- - -)\n",
      "3 (V - -) (V - -) (V - -) (- - -) (- - -)\n",
      "4 (- - -) (- - -) (- - -) (- - -) (- - -)\n",
      "Agent performance: 115\n",
      "PERCEPT\n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- - -) (- - -) (- - -) (- - -)\n",
      "1 (- - -) (- - 2) (- - -) (- - 1) (- - 1)\n",
      "2 (- - -) (- - -) (- 1 -) (L - -) (- - -)\n",
      "3 (- - -) (- - -) (- - -) (- - -) (- - -)\n",
      "4 (- - -) (- - -) (- - -) (- - -) (- - -)\n",
      "<STEP 16>\n",
      "SELECTED ACTION: Advance\n",
      "Agent state: (2, 2, Left)\n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (V - -) (V - -) (V - -) (V - -) (- - -)\n",
      "1 (V - -) (- - 2) (- - -) (V - 1) (- - 1)\n",
      "2 (V - -) (- - -) (V - -) (V - -) (- - -)\n",
      "3 (V - -) (V - -) (V - -) (- - -) (- - -)\n",
      "4 (- - -) (- - -) (- - -) (- - -) (- - -)\n",
      "Agent performance: 124\n",
      "PERCEPT\n",
      "     0       1       2       3       4\n",
      "  (A G T) (A G T) (A G T) (A G T) (A G T)\n",
      "0 (- - -) (- - -) (- - -) (- - -) (- - -)\n",
      "1 (- - -) (- - 2) (- - -) (- - 1) (- - 1)\n",
      "2 (- - -) (- - -) (L - -) (- - -) (- - -)\n",
      "3 (- - -) (- - -) (- - -) (- - -) (- - -)\n",
      "4 (- - -) (- - -) (- - -) (- - -) (- - -)\n"
     ]
    }
   ],
   "source": [
    "from agents import Environment, Thing, Agent, Direction, SimpleReflexAgentProgram\n",
    "from random import randrange, seed\n",
    "\n",
    "class GridEnvironment(Environment):\n",
    "    def __init__(self, fully_observable, things, agent):\n",
    "        super().__init__()\n",
    "        self.width  = 5\n",
    "        self.height  = 5\n",
    "        self.fully_observable = fully_observable\n",
    "        for thing in things:\n",
    "            self.things.append(thing)\n",
    "        self.things.append(agent)\n",
    "        self.agents.append(agent)\n",
    "        self.agent = agent\n",
    "        self.step_num = 0      \n",
    "        self.x_start, self.y_start = (0, 0)\n",
    "        self.x_end, self.y_end = (self.width, self.height)\n",
    "        \n",
    "    def print_environment_state(self, percept = False):\n",
    "        print(\"     0       1       2       3       4\")\n",
    "        print(\"  (A G T) (A G T) (A G T) (A G T) (A G T)\")\n",
    "        for y in range(0, 5):\n",
    "            state_msg = str(y)\n",
    "            for x in range(0, 5):\n",
    "                agent_dir = self.agent.direction.direction.capitalize()[0] if self.agent.location == (x, y) and percept else \"V\" if (x,y) in self.agent.visited_cells and not percept else \"-\"\n",
    "                gold_num = len(self.list_things_at((x, y), tclass = Gold)) if self.some_things_at((x, y), tclass = Gold) else \"-\"\n",
    "                traps_num = len(self.list_things_at((x, y), tclass = Trap)) if self.some_things_at((x, y), tclass = Trap) else \"-\"\n",
    "                state_msg += \" ({0} {1} {2})\".format(agent_dir, gold_num, traps_num) \n",
    "            print(state_msg)\n",
    "            \n",
    "    def print_percept(self):\n",
    "        print(\"PERCEPT\")\n",
    "        if self.fully_observable: \n",
    "            self.print_environment_state(percept = True)\n",
    "        else:\n",
    "            x , y = self.agent.location\n",
    "            x_min = x - 1 if self.is_inbounds((x - 1, y)) else x\n",
    "            x_max = x + 1 if self.is_inbounds((x + 1, y)) else x\n",
    "            y_min = y - 1 if self.is_inbounds((x, y - 1)) else y\n",
    "            y_max = y + 1 if self.is_inbounds((x, y + 1)) else y\n",
    "            \n",
    "            msg = \" \"\n",
    "            for x in range(x_min, x_max + 1):\n",
    "                msg += \"    {0}   \".format(x)\n",
    "            print(msg)\n",
    "            \n",
    "            msg = \" \"\n",
    "            for x in range(x_min, x_max + 1):\n",
    "                msg += \" (A G T)\"\n",
    "            print(msg)\n",
    "            \n",
    "            for y in range(y_min, y_max + 1):\n",
    "                msg = str(y)\n",
    "                for x in range(x_min, x_max + 1):\n",
    "                    agent_dir = self.agent.direction.direction.capitalize()[0] if self.agent.location == (x, y) else \"-\"\n",
    "                    gold_num = len(self.list_things_at((x, y), tclass = Gold)) if self.some_things_at((x, y), tclass = Gold) else \"-\"\n",
    "                    traps_num = len(self.list_things_at((x, y), tclass = Trap)) if self.some_things_at((x, y), tclass = Trap) else \"-\"\n",
    "                    msg += \" ({0} {1} {2})\".format(agent_dir, gold_num, traps_num) \n",
    "                print(msg)\n",
    "                \n",
    "    def step(self):\n",
    "        if self.step_num == 0:\n",
    "            print(\"<STARTING>\")\n",
    "            print(\"Agent state: ({0}, {1}, {2})\".format(self.agent.location[0], self.agent.location[1], self.agent.direction.direction.capitalize()))\n",
    "            self.print_environment_state()\n",
    "            print(\"Agent performance: {0}\".format(self.agent.performance))\n",
    "            self.print_percept()\n",
    "            \n",
    "        self.step_num += 1\n",
    "        \n",
    "        if not self.is_done():\n",
    "            print(\"<STEP {0}>\".format(self.step_num))\n",
    "            action = agent.program(self.percept(agent))\n",
    "            print(\"SELECTED ACTION: {0}\".format(action.capitalize()))\n",
    "            self.execute_action(agent, action)\n",
    "            print(\"Agent state: ({0}, {1}, {2})\".format(self.agent.location[0], self.agent.location[1], self.agent.direction.direction.capitalize()))\n",
    "            self.print_environment_state()\n",
    "            print(\"Agent performance: {0}\".format(self.agent.performance))\n",
    "            self.print_percept()\n",
    "        \n",
    "    def percept(self, agent):\n",
    "        if self.fully_observable:\n",
    "            percept = {}\n",
    "            percept[\"location\"] = agent.location\n",
    "            percept[\"direction\"] = agent.direction.direction\n",
    "            percept[\"things\"] = self.things\n",
    "            return percept\n",
    "        else:\n",
    "            x, y = agent.location\n",
    "            percept = {}\n",
    "            percept[\"location\"] = agent.location\n",
    "            percept[\"direction\"] = agent.direction\n",
    "            percept[\"things\"] = []\n",
    "            percept[\"things\"] +=  self.list_things_at((x , y)) if self.is_inbounds((x , y)) else []\n",
    "            percept[\"things\"] +=  self.list_things_at((x , y - 1)) if self.is_inbounds((x , y - 1)) else []\n",
    "            percept[\"things\"] +=  self.list_things_at((x + 1, y - 1)) if self.is_inbounds((x + 1, y - 1)) else []\n",
    "            percept[\"things\"] +=  self.list_things_at((x - 1 , y - 1)) if self.is_inbounds((x - 1 , y - 1)) else []\n",
    "            percept[\"things\"] +=  self.list_things_at((x , y + 1)) if self.is_inbounds((x , y + 1)) else []\n",
    "            percept[\"things\"] +=  self.list_things_at((x + 1 , y + 1)) if self.is_inbounds((x + 1 , y + 1)) else []\n",
    "            percept[\"things\"] +=  self.list_things_at((x - 1 , y + 1)) if self.is_inbounds((x - 1 , y + 1)) else []\n",
    "            percept[\"things\"] +=  self.list_things_at((x + 1, y)) if self.is_inbounds((x + 1 , y)) else [] \n",
    "            percept[\"things\"] +=  self.list_things_at((x - 1 , y)) if self.is_inbounds((x - 1 , y)) else []\n",
    "            \n",
    "            return percept\n",
    "        \n",
    "    def execute_action(self, agent, action):\n",
    "        if action == \"turn\":\n",
    "            agent.turn()\n",
    "        elif action == \"advance\":\n",
    "            new_location  = agent.direction.move_forward(agent.location) \n",
    "            outside_grid = not self.is_inbounds(new_location)\n",
    "            agent.advance(outside_grid)\n",
    "        elif action == \"stay\":\n",
    "            pass\n",
    "        self.process_things_in_cell(agent)\n",
    "\n",
    "    def process_things_in_cell(self, agent):\n",
    "        golds = self.list_things_at(agent.location, tclass = Gold)\n",
    "        if len(golds) != 0:\n",
    "            if agent.dig(golds[0]):\n",
    "                self.delete_thing(golds[0])\n",
    "        traps = self.list_things_at(agent.location, tclass = Trap)\n",
    "        if len(traps) != 0:\n",
    "            if agent.get_trapped(traps[0]):\n",
    "                self.delete_thing(traps[0])      \n",
    "                \n",
    "    def is_inbounds(self, location):\n",
    "        x, y = location\n",
    "        return not (x < self.x_start or x > self.x_end or y < self.y_start or y > self.y_end)\n",
    "    \n",
    "    def is_done(self):\n",
    "        no_gold = not any(isinstance(thing, Gold) for thing in self.things)\n",
    "        dead_agents = not any(agent.is_alive() for agent in self.agents)\n",
    "        return dead_agents or no_gold\n",
    "        \n",
    "class Gold(Thing):\n",
    "    def __init__(self, location):\n",
    "        self.location = location\n",
    "        \n",
    "class Trap(Thing):\n",
    "    def __init__(self, location):\n",
    "        self.location = location\n",
    "        \n",
    "class GoldDigger(Agent):\n",
    "    def __init__(self, location, direction, program=None):\n",
    "        super().__init__(program)\n",
    "        self.location = location\n",
    "        self.direction = direction\n",
    "        self.performance = 100\n",
    "        self.visited_cells = [location]\n",
    "        state = []    \n",
    "        \n",
    "    def turn(self):\n",
    "        self.performance -= 1\n",
    "        self.direction += Direction.R\n",
    "        \n",
    "    def advance(self, outside_grid = False):\n",
    "        self.performance -= 1\n",
    "        if outside_grid: \n",
    "            return\n",
    "        self.location = self.direction.move_forward(self.location)\n",
    "        if self.location in self.visited_cells: \n",
    "            self.performance -=2\n",
    "        else:\n",
    "            self.visited_cells.append(self.location)\n",
    "            \n",
    "    def dig(self, thing):\n",
    "        if isinstance(thing, Gold):\n",
    "            self.performance += 10\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def get_trapped(self, thing):\n",
    "        if isinstance(thing, Trap):\n",
    "            self.performance -= 5\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def is_alive(self):\n",
    "        return self.performance > 0\n",
    "\n",
    "class Rule:\n",
    "    def __init__(self, state, action):\n",
    "        self.__state = state\n",
    "        self.action = action\n",
    "\n",
    "    def matches(self, state):\n",
    "        return self.__state == state\n",
    "    \n",
    "def interpret_input(percept):\n",
    "    location = percept[\"location\"]\n",
    "    direction = percept[\"direction\"]\n",
    "    things = percept[\"things\"]\n",
    "    \n",
    "    if any(thing for thing in things if thing.location == location and isinstance(thing, Gold)):\n",
    "        return \"FeelGold\"\n",
    "    if direction == Direction.U:\n",
    "        if not any(thing for thing in things if thing.location[1] < location[1]):\n",
    "            return \"FacingLimit\"\n",
    "        elif any(thing for thing in things if thing.location[1] < location[1] and isinstance(thing, Gold)):\n",
    "            return \"FacingGold\"\n",
    "        elif not any(thing for thing in things if thing.location[1] == location[1] - 1 and isinstance(thing, Trap)):\n",
    "            return \"FacingVoid\"\n",
    "        else:\n",
    "            return \"FacingTrap\"\n",
    "    elif direction == Direction.R:\n",
    "        if not any(thing for thing in things if thing.location[0] > location[0]):\n",
    "            return \"FacingLimit\"\n",
    "        elif any(thing for thing in things if thing.location[0] > location[0] and isinstance(thing, Gold)):\n",
    "            return \"FacingGold\"\n",
    "        elif not any(thing for thing in things if thing.location[0] == location[0] + 1 and isinstance(thing, Trap)):\n",
    "            return \"FacingVoid\"\n",
    "        else:\n",
    "            return \"FacingTrap\"\n",
    "    elif direction == Direction.D:\n",
    "        if not any(thing for thing in things if thing.location[1] > location[1]):\n",
    "            return \"FacingLimit\"\n",
    "        elif any(thing for thing in things if thing.location[1] > location[1] and isinstance(thing, Gold)):\n",
    "            return \"FacingGold\"\n",
    "        elif not any(thing for thing in things if thing.location[1] == location[1] + 1 and isinstance(thing, Trap)):\n",
    "            return \"FacingVoid\"\n",
    "        else:\n",
    "            return \"FacingTrap\"\n",
    "    elif direction == Direction.L:\n",
    "        if not any(thing for thing in things if thing.location[0] < location[0]):\n",
    "            return \"FacingLimit\"\n",
    "        elif any(thing for thing in things if thing.location[0] < location[0] and isinstance(thing, Gold)):\n",
    "            return \"FacingGold\"\n",
    "        elif not any(thing for thing in things if thing.location[0] == location[0] - 1 and isinstance(thing, Trap)):\n",
    "            return \"FacingVoid\"\n",
    "        else:\n",
    "            return \"FacingTrap\"\n",
    "\n",
    "# seed(0)\n",
    "rules = [Rule(\"FeelGold\", \"stay\"), Rule(\"FacingGold\", \"advance\"), Rule(\"FacingTrap\", \"turn\"), Rule(\"FacingLimit\", \"turn\"), Rule(\"FacingVoid\", \"advance\")]\n",
    "simple_reflex_agent_program = SimpleReflexAgentProgram(rules, interpret_input)\n",
    "\n",
    "total_golds = 5\n",
    "total_traps = 6\n",
    "things = []\n",
    "while total_golds > 0:\n",
    "    total_golds -= 1\n",
    "    x = randrange(4)\n",
    "    y = randrange(4)\n",
    "    things.append(Gold((x,y)))\n",
    "while total_traps > 0:\n",
    "    total_traps -= 1\n",
    "    x = randrange(5)\n",
    "    y = randrange(5)\n",
    "    things.append(Trap((x,y)))\n",
    "            \n",
    "DIRS = [Direction.U, Direction.R, Direction.D, Direction.L]\n",
    "agent_x = randrange(4)\n",
    "agent_y = randrange(4)\n",
    "agent_dir = DIRS[randrange(3)]\n",
    "\n",
    "agent = GoldDigger((agent_x, agent_y), Direction(agent_dir), simple_reflex_agent_program)\n",
    "\n",
    "environment = GridEnvironment(fully_observable = True, things = things, agent = agent)\n",
    "\n",
    "environment.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
